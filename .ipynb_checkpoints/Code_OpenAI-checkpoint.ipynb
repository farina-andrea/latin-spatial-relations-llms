{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f93753c",
   "metadata": {},
   "source": [
    "# Spatial relations in Latin preverbed motion verbs using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3198b",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"#key#\")\n",
    "\n",
    "#test\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\", \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c20a8",
   "metadata": {},
   "source": [
    "Input files here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951627c",
   "metadata": {},
   "source": [
    "## Read annotated texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb650fd3",
   "metadata": {},
   "source": [
    "Create a data frame with the annotated texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc527bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = pd.read_csv(annotated_texts, header = 0)\n",
    "annotated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d21d0",
   "metadata": {},
   "source": [
    "As the `annotated`dataset includes both Ancient Greek and Latin, I filter out Greek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74987adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_Latin_preverbs = ['ad', 'ex', 'per', 'in', 'cum', 'ab', 'trans', 'sub', 'ob', 'pro']\n",
    "annotated_Latin = annotated[annotated['PREVERB'].isin(selected_Latin_preverbs) & (annotated['language'] == 'Latin')]\n",
    "annotated_Latin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b5caf",
   "metadata": {},
   "source": [
    "I filter out rows where no spatial relations occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_Latin_filtered = annotated_Latin[annotated_Latin['SPATIAL RELATION ROLE'].notna()]\n",
    "annotated_Latin_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31296a1",
   "metadata": {},
   "source": [
    "# Task 1 (OpenAI): identify motion verbs in the sentence (LATIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompts(df, sentence, verb, preverb, number_of_shots, input_col='SENTENCE', gold_standard_col='VERB TOKEN'):\n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. Given the following Latin sentences, \"\n",
    "        f\"identify all the forms of the verb '{verb}' across all sentences. \"\n",
    "        f\"Note that verbs may occur more than once and in more than one sentence, \"\n",
    "        f\"so PROVIDE ALL THE FORMS YOU DETECT.\"\n",
    "    )\n",
    "\n",
    "    if number_of_shots > 0:\n",
    "        shots = df.sample(n=number_of_shots, random_state=42)\n",
    "        examples = [\n",
    "            f\"Sentence: {row[input_col]}\\nAnswer: {row[gold_standard_col]}\"\n",
    "            for _, row in shots.iterrows()\n",
    "        ]\n",
    "        prompt += \"\\n\\n\" + \"\\n\\n\".join(examples)\n",
    "\n",
    "    prompt += f\"\\n\\nSentence: {sentence}\\nAnswer:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for row_num, (idx, row) in enumerate(annotated_Latin_filtered.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(annotated_Latin_filtered)}\")\n",
    "\n",
    "    try:\n",
    "        prompt = make_prompts(\n",
    "            annotated_Latin_filtered,\n",
    "            row['SENTENCE'],\n",
    "            row['LEMMA'],\n",
    "            row['PREVERB'],\n",
    "            number_of_shots=0,\n",
    "            input_col='SENTENCE',\n",
    "            gold_standard_col='VERB TOKEN'\n",
    "        )\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        prediction = content if content else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row_num}: {e}\")\n",
    "        prediction = \"ERROR\"\n",
    "\n",
    "    responses.append(prediction)\n",
    "    annotated_Latin_filtered.loc[idx, 'predicted'] = prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6609c",
   "metadata": {},
   "source": [
    "## One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827738ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompts(df, sentence, verb, preverb, number_of_shots, input_col='SENTENCE', gold_standard_col='VERB TOKEN'):\n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. Given the following Latin sentences, \"\n",
    "        f\"identify all the forms of the verb '{verb}' across all sentences. \"\n",
    "        f\"Note that verbs may occur more than once and in more than one sentence, \"\n",
    "        f\"so PROVIDE ALL THE FORMS YOU DETECT.\"\n",
    "    )\n",
    "\n",
    "    if number_of_shots > 0:\n",
    "        shots = df.sample(n=number_of_shots, random_state=42)\n",
    "        examples = [\n",
    "            f\"Sentence: {row[input_col]}\\nAnswer: {row[gold_standard_col]}\"\n",
    "            for _, row in shots.iterrows()\n",
    "        ]\n",
    "        prompt += \"\\n\\n\" + \"\\n\\n\".join(examples)\n",
    "\n",
    "    prompt += f\"\\n\\nSentence: {sentence}\\nAnswer:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for row_num, (idx, row) in enumerate(annotated_Latin_filtered.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(annotated_Latin_filtered)}\")\n",
    "\n",
    "    try:\n",
    "        prompt = make_prompts(\n",
    "            annotated_Latin_filtered,\n",
    "            row['SENTENCE'],\n",
    "            row['LEMMA'],\n",
    "            row['PREVERB'],\n",
    "            number_of_shots=1,\n",
    "            input_col='SENTENCE',\n",
    "            gold_standard_col='VERB TOKEN'\n",
    "        )\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        prediction = content if content else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row_num}: {e}\")\n",
    "        prediction = \"ERROR\"\n",
    "\n",
    "    responses.append(prediction)\n",
    "    annotated_Latin_filtered.loc[idx, 'predicted'] = prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdc417",
   "metadata": {},
   "source": [
    "## Five shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc748aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompts(df, sentence, verb, preverb, number_of_shots, input_col='SENTENCE', gold_standard_col='VERB TOKEN'):\n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. Given the following Latin sentences, \"\n",
    "        f\"identify all the forms of the verb '{verb}' across all sentences. \"\n",
    "        f\"Note that verbs may occur more than once and in more than one sentence, \"\n",
    "        f\"so PROVIDE ALL THE FORMS YOU DETECT.\"\n",
    "    )\n",
    "\n",
    "    if number_of_shots > 0:\n",
    "        shots = df.sample(n=number_of_shots, random_state=42)\n",
    "        examples = [\n",
    "            f\"Sentence: {row[input_col]}\\nAnswer: {row[gold_standard_col]}\"\n",
    "            for _, row in shots.iterrows()\n",
    "        ]\n",
    "        prompt += \"\\n\\n\" + \"\\n\\n\".join(examples)\n",
    "\n",
    "    prompt += f\"\\n\\nSentence: {sentence}\\nAnswer:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e412927",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for row_num, (idx, row) in enumerate(annotated_Latin_filtered.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(annotated_Latin_filtered)}\")\n",
    "\n",
    "    try:\n",
    "        prompt = make_prompts(\n",
    "            annotated_Latin_filtered,\n",
    "            row['SENTENCE'],\n",
    "            row['LEMMA'],\n",
    "            row['PREVERB'],\n",
    "            number_of_shots=5,\n",
    "            input_col='SENTENCE',\n",
    "            gold_standard_col='VERB TOKEN'\n",
    "        )\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        prediction = content if content else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row_num}: {e}\")\n",
    "        prediction = \"ERROR\"\n",
    "\n",
    "    responses.append(prediction)\n",
    "    annotated_Latin_filtered.loc[idx, 'predicted'] = prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed3df5b",
   "metadata": {},
   "source": [
    "# Task 2 (OpenAI): is there a place expression in the sentence occurring with these motion verbs and if so, does it express Goal/Source/Path? (LATIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompts(\n",
    "    df,\n",
    "    sentence,\n",
    "    verb,\n",
    "    preverb,\n",
    "    number_of_shots,\n",
    "    input_col='SENTENCE',\n",
    "    gold_standard_col='VERB TOKEN',\n",
    "    gold_standard_col_source='source',\n",
    "    gold_standard_col_goal='goal',\n",
    "    gold_standard_col_path='path'\n",
    "):\n",
    "\n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. Given the following Latin sentences, \"\n",
    "        f\"identify all the forms of the verb '{verb}' across all sentences. \"\n",
    "        f\"Note that verbs may occur more than once and in more than one sentence, \"\n",
    "        f\"so PROVIDE ALL THE FORMS YOU DETECT.\\n\"\n",
    "        f\"Then, additionally answer:\\n\"\n",
    "        f\"- Does the sentence contain a **source expression**? True or False\\n\"\n",
    "        f\"- Does the sentence contain a **goal expression**? True or False\\n\"\n",
    "        f\"- Does the sentence contain a **path expression**? True or False\"\n",
    "    )\n",
    "\n",
    "    if number_of_shots > 0:\n",
    "        shots = df.sample(n=number_of_shots, random_state=42)\n",
    "        examples = []\n",
    "        for _, row in shots.iterrows():\n",
    "            example = (\n",
    "                f\"\\n\\nSentence: {row[input_col]}\\n\"\n",
    "                f\"Answer:\\n{row[gold_standard_col]}\\n\"\n",
    "                f\"- Source expression: {row[gold_standard_col_source]}\\n\"\n",
    "                f\"- Goal expression: {row[gold_standard_col_goal]}\\n\"\n",
    "                f\"- Path expression: {row[gold_standard_col_path]}\"\n",
    "            )\n",
    "            examples.append(example)\n",
    "        prompt += \"\".join(examples)\n",
    "\n",
    "    prompt += (\n",
    "        f\"\\n\\nSentence: {sentence}\\nAnswer:\\n\\n\"\n",
    "        f\"List all forms of the verb '{verb}' you find in the sentence.\\n\\n\"\n",
    "        f\"Then answer as follows:\\n\"\n",
    "        f\"- Source expression: True or False\\n\"\n",
    "        f\"- Goal expression: True or False\\n\"\n",
    "        f\"- Path expression: True or False\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9f8bf",
   "metadata": {},
   "source": [
    "## Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through rows and get GPT answers\n",
    "for row_num, (idx, row) in enumerate(annotated_Latin_filtered.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(annotated_Latin_filtered)}\")\n",
    "\n",
    "    try:\n",
    "        prompt = make_prompts(\n",
    "            annotated_Latin_filtered,\n",
    "            row['SENTENCE'],\n",
    "            row['LEMMA'],\n",
    "            row['PREVERB'],\n",
    "            number_of_shots=0,  \n",
    "            input_col='SENTENCE',\n",
    "            gold_standard_col='VERB TOKEN',\n",
    "            gold_standard_col_source='source',\n",
    "            gold_standard_col_goal='goal',\n",
    "            gold_standard_col_path='path'\n",
    "        )\n",
    "\n",
    "        # Send to GPT-4\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a Latin linguistics expert. Always follow the format requested.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted'] = content\n",
    "\n",
    "\n",
    "        source_flag, goal_flag, path_flag = extract_boolean_flags(content)\n",
    "\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_source'] = str(source_flag)\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_goal'] = str(goal_flag)\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_path'] = str(path_flag)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row_num}: {e}\")\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_source'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_goal'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_path'] = \"ERROR\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1dd2f",
   "metadata": {},
   "source": [
    "## One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ba1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boolean_flags(response_content):\n",
    "    try:\n",
    "        source = re.search(r\"source expression:\\s*(true|false)\", response_content, re.IGNORECASE)\n",
    "        goal = re.search(r\"goal expression:\\s*(true|false)\", response_content, re.IGNORECASE)\n",
    "        path = re.search(r\"path expression:\\s*(true|false)\", response_content, re.IGNORECASE)\n",
    "\n",
    "        return (\n",
    "            source.group(1).lower() == \"true\" if source else False,\n",
    "            goal.group(1).lower() == \"true\" if goal else False,\n",
    "            path.group(1).lower() == \"true\" if path else False,\n",
    "        )\n",
    "    except:\n",
    "        return (False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18772a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_num, (idx, row) in enumerate(annotated_Latin_filtered.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(annotated_Latin_filtered)}\")\n",
    "\n",
    "    try:\n",
    "        prompt = make_prompts(\n",
    "            annotated_Latin_filtered,\n",
    "            row['SENTENCE'],\n",
    "            row['LEMMA'],\n",
    "            row['PREVERB'],\n",
    "            number_of_shots=1,  \n",
    "            input_col='SENTENCE',\n",
    "            gold_standard_col='VERB TOKEN',\n",
    "            gold_standard_col_source='source',\n",
    "            gold_standard_col_goal='goal',\n",
    "            gold_standard_col_path='path'\n",
    "        )\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a Latin linguistics expert. Always follow the format requested.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted'] = content\n",
    "\n",
    "        source_flag, goal_flag, path_flag = extract_boolean_flags(content)\n",
    "\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_source'] = str(source_flag)\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_goal'] = str(goal_flag)\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_path'] = str(path_flag)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row_num}: {e}\")\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_source'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_goal'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_path'] = \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95105f2",
   "metadata": {},
   "source": [
    "## Few shots: 3 (one \"True\" per spatial relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fad311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompts_3_shot(df, sentence, verb, preverb, input_col='SENTENCE', gold_standard_col='VERB TOKEN', gold_standard_col_source='source', gold_standard_col_goal='goal', gold_standard_col_path='path'):\n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. Given the following Latin sentences, \"\n",
    "        f\"identify all the forms of the verb '{verb}' across all sentences.\\n\"\n",
    "        f\"Then, additionally answer:\\n\"\n",
    "        f\"- Does the sentence contain a **source expression**? True or False\\n\"\n",
    "        f\"- Does the sentence contain a **goal expression**? True or False\\n\"\n",
    "        f\"- Does the sentence contain a **path expression**? True or False\"\n",
    "    )\n",
    "\n",
    "    conditions = {\n",
    "        'source': gold_standard_col_source,\n",
    "        'goal': gold_standard_col_goal,\n",
    "        'path': gold_standard_col_path\n",
    "    }\n",
    "    \n",
    "    for label, col in conditions.items():\n",
    "        ex = df[df[col] == True].sample(n=1, random_state=42)\n",
    "        for _, row in ex.iterrows():\n",
    "            prompt += (\n",
    "                f\"\\n\\nSentence: {row[input_col]}\\n\"\n",
    "                f\"Answer:\\n{row[gold_standard_col]}\\n\"\n",
    "                f\"- Source expression: {row[gold_standard_col_source]}\\n\"\n",
    "                f\"- Goal expression: {row[gold_standard_col_goal]}\\n\"\n",
    "                f\"- Path expression: {row[gold_standard_col_path]}\"\n",
    "            )\n",
    "\n",
    "    prompt += (\n",
    "        f\"\\n\\nSentence: {sentence}\\nAnswer:\\n\\n\"\n",
    "        f\"List all forms of the verb '{verb}' you find in the sentence.\\n\\n\"\n",
    "        f\"Then answer as follows:\\n\"\n",
    "        f\"- Source expression: True or False\\n\"\n",
    "        f\"- Goal expression: True or False\\n\"\n",
    "        f\"- Path expression: True or False\\n\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boolean_flags(response_content):\n",
    "    try:\n",
    "        source = re.search(r\"source expression:\\s*(true|false)\", response_content, re.IGNORECASE)\n",
    "        goal = re.search(r\"goal expression:\\s*(true|false)\", response_content, re.IGNORECASE)\n",
    "        path = re.search(r\"path expression:\\s*(true|false)\", response_content, re.IGNORECASE)\n",
    "\n",
    "        return (\n",
    "            source.group(1).lower() == \"true\" if source else False,\n",
    "            goal.group(1).lower() == \"true\" if goal else False,\n",
    "            path.group(1).lower() == \"true\" if path else False,\n",
    "        )\n",
    "    except:\n",
    "        return (False, False, False)\n",
    "\n",
    "for row_num, (idx, row) in enumerate(annotated_Latin_filtered.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(annotated_Latin_filtered)}\")\n",
    "\n",
    "    try:\n",
    "        prompt = make_prompts_3_shot(\n",
    "            annotated_Latin_filtered,\n",
    "            row['SENTENCE'],\n",
    "            row['LEMMA'],\n",
    "            row['PREVERB'],\n",
    "            input_col='SENTENCE',\n",
    "            gold_standard_col='VERB TOKEN',\n",
    "            gold_standard_col_source='source',\n",
    "            gold_standard_col_goal='goal',\n",
    "            gold_standard_col_path='path'\n",
    "        )\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a Latin linguistics expert. Always follow the format requested.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted'] = content\n",
    "\n",
    "        source_flag, goal_flag, path_flag = extract_boolean_flags(content)\n",
    "\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_source'] = str(source_flag)\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_goal'] = str(goal_flag)\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_path'] = str(path_flag)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row_num}: {e}\")\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_source'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_goal'] = \"ERROR\"\n",
    "        annotated_Latin_filtered.loc[idx, 'predicted_path'] = \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff17f9",
   "metadata": {},
   "source": [
    "## Few shots: 6 (two shots per spatial relation, one \"True\" and one \"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompts_6_shot(\n",
    "    df,\n",
    "    sentence,\n",
    "    verb,\n",
    "    preverb,\n",
    "    input_col='SENTENCE',\n",
    "    gold_standard_col='VERB TOKEN',\n",
    "    gold_standard_col_source='source',\n",
    "    gold_standard_col_goal='goal',\n",
    "    gold_standard_col_path='path'\n",
    "):\n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. Given the following Latin sentences, \"\n",
    "        f\"identify all the forms of the verb '{verb}' across all sentences.\\n\"\n",
    "        f\"Then, additionally answer:\\n\"\n",
    "        f\"- Does the sentence contain a **source expression**? True or False\\n\"\n",
    "        f\"- Does the sentence contain a **goal expression**? True or False\\n\"\n",
    "        f\"- Does the sentence contain a **path expression**? True or False\"\n",
    "    )\n",
    "\n",
    "    # Balanced sampling: 1 True and 1 False example for each relation\n",
    "    conditions = {\n",
    "        'source': gold_standard_col_source,\n",
    "        'goal': gold_standard_col_goal,\n",
    "        'path': gold_standard_col_path\n",
    "    }\n",
    "\n",
    "    for label, col in conditions.items():\n",
    "        true_example = df[df[col] == True].sample(n=1, random_state=42)\n",
    "        false_example = df[df[col] == False].sample(n=1, random_state=99)\n",
    "\n",
    "        for subset in [true_example, false_example]:\n",
    "            for _, row in subset.iterrows():\n",
    "                prompt += (\n",
    "                    f\"\\n\\nSentence: {row[input_col]}\\n\"\n",
    "                    f\"Answer:\\n{row[gold_standard_col]}\\n\"\n",
    "                    f\"- Source expression: {row[gold_standard_col_source]}\\n\"\n",
    "                    f\"- Goal expression: {row[gold_standard_col_goal]}\\n\"\n",
    "                    f\"- Path expression: {row[gold_standard_col_path]}\"\n",
    "                )\n",
    "\n",
    "    prompt += (\n",
    "        f\"\\n\\nSentence: {sentence}\\nAnswer:\\n\\n\"\n",
    "        f\"List all forms of the verb '{verb}' you find in the sentence.\\n\\n\"\n",
    "        f\"Then answer as follows:\\n\"\n",
    "        f\"- Source expression: True or False\\n\"\n",
    "        f\"- Goal expression: True or False\\n\"\n",
    "        f\"- Path expression: True or False\\n\"\n",
    "    )\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a316dc",
   "metadata": {},
   "source": [
    "## Task 3 (OpenAI): common/proper noun disambiguation with spatial relations (LATIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38edd1",
   "metadata": {},
   "source": [
    "## Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f120135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_place_disambiguation_prompt(sentence, relation_type, verb):\n",
    "    return (\n",
    "        f\"This is a Latin linguistics task.\\n\"\n",
    "        f\"You are given a sentence and a specific motion verb '{verb}'.\\n\"\n",
    "        f\"Your job is to identify the single word (token) in '{sentence}' that:\\n\"\n",
    "        f\"  - Is a direct argument of the verb '{verb}'\\n\"\n",
    "        f\"  - Expresses the spatial relation '{relation_type}' (Source, Goal, or Path) with respect to this verb\\n\"\n",
    "        f\"  - And is either an adverb, a common noun referring to a place, or a proper noun referring to a place name\\n\\n\"\n",
    "        f\"Ignore any other place names or nouns that do not have this syntactic and semantic relation with '{verb}'.\\n\"\n",
    "        f\"Answer with exactly two lines, no extra text:\\n\"\n",
    "        f\"Token: <token>\\n\"\n",
    "        f\"adverb | common noun | proper noun\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4344d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_num, (idx, row) in enumerate(task3_ready_df.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(task3_ready_df)}\")\n",
    "\n",
    "    for relation in ['predicted_source', 'predicted_goal', 'predicted_path']:\n",
    "        if row.get(relation) == True:\n",
    "            prompt = make_place_disambiguation_prompt(row['SENTENCE'], relation, row['LEMMA'])\n",
    "            \n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a Latin linguist.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0\n",
    "                )\n",
    "                content = response.choices[0].message.content.strip()\n",
    "            \n",
    "                token_match = re.search(r\"Token:\\s*(\\S+)\", content, re.IGNORECASE)\n",
    "                type_match = re.search(r\"\\b(adverb|common noun|proper noun)\\b\", content, re.IGNORECASE)\n",
    "\n",
    "                token = token_match.group(1) if token_match else None\n",
    "                typ = type_match.group(1).lower() if type_match else None\n",
    "\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_token'] = token\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_type'] = typ\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}, relation {relation}: {e}\")\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_type'] = \"ERROR\"\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_token'] = None\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b7b81",
   "metadata": {},
   "source": [
    "## One shot (proper nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "def make_place_disambiguation_prompt(sentence, relation_type, verb, df):\n",
    "    # Select one random example with SR_type == 'proper noun'\n",
    "    proper_noun_rows = df[df['SR_type'] == 'proper noun']\n",
    "    if proper_noun_rows.empty:\n",
    "        raise ValueError(\"No proper noun examples found in the DataFrame.\")\n",
    "    \n",
    "    example_row = proper_noun_rows.sample(1).iloc[0]\n",
    "    example_sentence = example_row['SENTENCE']\n",
    "    example_verb = example_row['LEMMA']\n",
    "    example_place_token = example_row.get('SR_token', '<place_token>')\n",
    "    \n",
    "    example = (\n",
    "        \"Example:\\n\"\n",
    "        f\"Sentence: {example_sentence}\\n\"\n",
    "        f\"Verb: {example_verb}\\n\"\n",
    "        f\"Relation: predicted_source\\n\"\n",
    "        f\"Answer:\\n\"\n",
    "        f\"Token: {example_place_token}\\n\"\n",
    "        f\"proper noun\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    prompt = (\n",
    "        f\"This is a task of Latin linguistics. You are given a Latin sentence and a motion verb.\\n\"\n",
    "        f\"Focus only on the expression that refers to the spatial relation of type '{relation_type}' \"\n",
    "        f\"in relation to the verb '{verb}'.\\n\"\n",
    "        f\"Identify the word (token) in the sentence that expresses this spatial relation, \"\n",
    "        f\"and classify it as:\\n\"\n",
    "        f\"- adverb\\n\"\n",
    "        f\"- common noun referring to a place (e.g., 'domus', 'forum')\\n\"\n",
    "        f\"- proper noun referring to a place (e.g., 'Roma', 'Carthago')\\n\\n\"\n",
    "        f\"{example}\"\n",
    "        f\"Now analyze the following sentence.\\n\"\n",
    "        f\"Sentence: {sentence}\\n\"\n",
    "        f\"Verb: {verb}\\n\"\n",
    "        f\"Relation: {relation_type}\\n\"\n",
    "        f\"Answer:\\n\"\n",
    "        f\"Token: <token>\\n\"\n",
    "        f\"[adverb | common noun | proper noun]\"\n",
    "    )\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row_num, (idx, row) in enumerate(task3_ready_df.iterrows(), start=1):\n",
    "    if row_num % 10 == 0:\n",
    "        print(f\"Processing row {row_num} of {len(task3_ready_df)}\")\n",
    "    \n",
    "    for relation in ['predicted_source', 'predicted_goal', 'predicted_path']:\n",
    "        if row.get(relation) is True:\n",
    "            prompt = make_place_disambiguation_prompt(\n",
    "                row['SENTENCE'],\n",
    "                relation,\n",
    "                row['LEMMA'],\n",
    "                task3_ready_df\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a Latin linguist.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0\n",
    "                )\n",
    "                \n",
    "                content = response.choices[0].message.content.strip()\n",
    "                token_match = re.search(r\"Token:\\s*(\\S+)\", content, re.IGNORECASE)\n",
    "                type_match = re.search(r\"\\b(adverb|common noun|proper noun)\\b\", content, re.IGNORECASE)\n",
    "                \n",
    "                token = token_match.group(1) if token_match else None\n",
    "                typ = type_match.group(1).lower() if type_match else None\n",
    "                \n",
    "                task3_ready_df.loc[idx, 'predicted_SR_token'] = token\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_type'] = typ\n",
    "                break  # Stop after first matching relation\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}, relation {relation}: {e}\")\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_type'] = \"ERROR\"\n",
    "                task3_ready_df.loc[idx, 'predicted_SR_token'] = None\n",
    "                break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
